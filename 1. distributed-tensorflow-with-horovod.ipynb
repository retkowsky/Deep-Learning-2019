{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Distributed Tensorflow with Horovod\nIn this tutorial, you will train a word2vec model in TensorFlow using distributed training via [Horovod](https://github.com/uber/horovod)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Check core SDK version number\nimport azureml.core\n\nprint(\"SDK version:\", azureml.core.VERSION)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "SDK version: 1.0.2\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Diagnostics\nOpt-in diagnostics for better experience, quality, and security of future releases."
    },
    {
      "metadata": {
        "tags": [
          "Diagnostics"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.telemetry import set_diagnostics_collection\n\nset_diagnostics_collection(send_diagnostics=True)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Initialize workspace\nInitialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.workspace import Workspace\n\nws = Workspace.from_config()\nprint('Workspace name: ' + ws.name, \n      'Azure region: ' + ws.location, \n      'Subscription id: ' + ws.subscription_id, \n      'Resource group: ' + ws.resource_group, sep = '\\n')",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found the config file in: /home/nbuser/library/aml_config/config.json\nWorkspace name: AMLSworkspace\nAzure region: westeurope\nSubscription id: 70b8f39e-8863-49f7-b6ba-34a80799550c\nResource group: resgrpAMLS\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create a remote compute target\nYou will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) to execute your training script on. In this tutorial, you create an `AmlCompute` cluster as your training compute resource. This code creates a cluster for you if it does not already exist in your workspace.\n\n**Creation of the cluster takes approximately 5 minutes.** If the cluster is already in your workspace this code will skip the cluster creation process."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\n\n# choose a name for your cluster\ncluster_name = \"gpucluster\"\n\ntry:\n    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n    print('Found existing compute target')\nexcept ComputeTargetException:\n    print('Creating a new compute target...')\n    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n                                                           max_nodes=4)\n\n    # create the cluster\n    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n\n    compute_target.wait_for_completion(show_output=True)\n\n# Use the 'status' property to get a detailed status for the current cluster. \nprint(compute_target.status.serialize())",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found existing compute target\n{'allocationState': 'Resizing', 'allocationStateTransitionTime': '2018-12-26T13:37:22.850000+00:00', 'creationTime': '2018-12-10T16:09:58.703952+00:00', 'currentNodeCount': 2, 'errors': [{'code': 'ClusterCoreQuotaReached', 'message': 'Operation results in exceeding quota limits of Total Cluster Dedicated Regional vCPUs. Maximum allowed: 24, Current in use: 14, Additional requested: 12. Please contact support to increase the quota for resource type Total Cluster Dedicated Regional vCPUs', 'error': {'code': 'ClusterCoreQuotaReached', 'message': 'Operation results in exceeding quota limits of Total Cluster Dedicated Regional vCPUs. Maximum allowed: 24, Current in use: 14, Additional requested: 12. Please contact support to increase the quota for resource type Total Cluster Dedicated Regional vCPUs'}}], 'modifiedTime': '2018-12-10T16:11:24.446527+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 0, 'runningNodeCount': 2, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 3, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The above code creates a GPU cluster. If you instead want to create a CPU cluster, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Upload data to datastore\nTo make data accessible for remote training, AML provides a convenient way to do so via a [Datastore](https://docs.microsoft.com/azure/machine-learning/service/how-to-access-data). The datastore provides a mechanism for you to upload/download data to Azure Storage, and interact with it from your remote compute targets. \n\nIf your data is already stored in Azure, or you download the data as part of your training script, you will not need to do this step. For this tutorial, although you can download the data in your training script, we will demonstrate how to upload the training data to a datastore and access it during training to illustrate the datastore functionality."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "First, download the training data from [here](http://mattmahoney.net/dc/text8.zip) to your local machine:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport urllib\n\nos.makedirs('./data', exist_ok=True)\ndownload_url = 'http://mattmahoney.net/dc/text8.zip'\nurllib.request.urlretrieve(download_url, filename='./data/text8.zip')",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "('./data/text8.zip', <http.client.HTTPMessage at 0x7fc26e89c780>)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Each workspace is associated with a default datastore. In this tutorial, we will upload the training data to this default datastore."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ds = ws.get_default_datastore()\nprint(ds.datastore_type, ds.account_name, ds.container_name)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "AzureBlob amlsworkspace9663571855 azureml-blobstore-4446f3c5-7943-4ab5-b1f3-5e4c7ede791c\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Upload the contents of the data directory to the path `./data` on the default datastore."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ds.upload(src_dir='data', target_path='data', overwrite=True, show_progress=True)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_baa221bf55dc4ef5abfc62c70a0ff449"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "For convenience, let's get a reference to the path on the datastore with the zip file of training data. We can do so using the `path` method. In the next section, we can then pass this reference to our training script's `--input_data` argument. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "path_on_datastore = 'data/text8.zip'\nds_data = ds.path(path_on_datastore)\nprint(ds_data)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "$AZUREML_DATAREFERENCE_3c18fcc578b242b1a5baa22c0860b576\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train model on the remote compute"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create a project directory\nCreate a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script, and any additional files your training script depends on."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\n\nproject_folder = './tf-distr-hvd'\nos.makedirs(project_folder, exist_ok=True)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copy the training script `tf_horovod_word2vec.py` into this project directory."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import shutil\n\nshutil.copy('tf_horovod_word2vec.py', project_folder)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "'./tf-distr-hvd/tf_horovod_word2vec.py'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create an experiment\nCreate an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this distributed TensorFlow tutorial. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Experiment\n\nexperiment_name = 'tf-distr-hvd'\nexperiment = Experiment(ws, name=experiment_name)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create a TensorFlow estimator\nThe AML SDK's TensorFlow estimator enables you to easily submit TensorFlow training jobs for both single-node and distributed runs. For more information on the TensorFlow estimator, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-train-tensorflow)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.train.dnn import TensorFlow\n\nscript_params={\n    '--input_data': ds_data\n}\n\nestimator= TensorFlow(source_directory=project_folder,\n                      compute_target=compute_target,\n                      script_params=script_params,\n                      entry_script='tf_horovod_word2vec.py',\n                      node_count=2,\n                      process_count_per_node=1,\n                      distributed_backend='mpi',\n                      use_gpu=True)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The above code specifies that we will run our training script on `2` nodes, with one worker per node. In order to execute a distributed run using MPI/Horovod, you must provide the argument `distributed_backend='mpi'`. Using this estimator with these settings, TensorFlow, Horovod and their dependencies will be installed for you. However, if your script also uses other packages, make sure to install them via the `TensorFlow` constructor's `pip_packages` or `conda_packages` parameters.\n\nNote that we passed our training data reference `ds_data` to our script's `--input_data` argument. This will 1) mount our datastore on the remote compute and 2) provide the path to the data zip file on our datastore."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Submit job\nRun your experiment by submitting your estimator object. Note that this call is asynchronous."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run = experiment.submit(estimator)\nprint(run)",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run(Experiment: tf-distr-hvd,\nId: tf-distr-hvd_1545831657015,\nType: azureml.scriptrun,\nStatus: Queued)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Monitor your run\nYou can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(run).show()",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1763bb68149c4bc5b1890b11bc14ff13",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Alternatively, you can block until the script has completed training before running more code."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run.wait_for_completion(show_output=True)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "RunId: tf-distr-hvd_1545831657015\n\nStreaming azureml-logs/80_driver_log_rank_0.txt\n===============================================\n\nthe input data is at /mnt/batch/tasks/shared/LS_root/jobs/amlsworkspace/azureml/tf-distr-hvd_1545831657015/mounts/workspaceblobstore/data/text8.zip\nUse the data from /mnt/batch/tasks/shared/LS_root/jobs/amlsworkspace/azureml/tf-distr-hvd_1545831657015/mounts/workspaceblobstore/data/text8.zip\nFound and verified /mnt/batch/tasks/shared/LS_root/jobs/amlsworkspace/azureml/tf-distr-hvd_1545831657015/mounts/workspaceblobstore/data/text8.zip\nData size 17005207\nMost common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\nSample data [5234, 3081, 12, 6, 195, 2, 3134, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n16 five -> 9 nine\n16 five -> 4 one\n4 one -> 16 five\n4 one -> 2316 featuring\n2316 featuring -> 1 the\n2316 featuring -> 4 one\n1 the -> 2316 featuring\n1 the -> 299 best\nWARNING:tensorflow:From tf_horovod_word2vec.py:195: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\nInstructions for updating:\nkeep_dims is deprecated, use keepdims instead\n2018-12-26 13:57:28.788396: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-12-26 13:57:28.899231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 8ad0:00:00.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2018-12-26 13:57:28.899273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n2018-12-26 13:57:29.161957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-12-26 13:57:29.162014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n2018-12-26 13:57:29.162026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n2018-12-26 13:57:29.162305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 8ad0:00:00.0, compute capability: 3.7)\nInitialized\nAverage loss at step  0 :  295.21026611328125\nAverage loss at step  2000 :  87.08666372942925\nNearest to not: homepage, sheet, dativus, monterey, claimed, sing, comparable, ecology,\nNearest to will: writing, dolphin, monterey, growth, jew, massachusetts, concurrent, added,\nNearest to is: in, ethics, pl, malaria, dolphin, dativus, rover, falkland,\nNearest to nine: ecology, concurrent, monterey, honda, glue, columbus, dativus, grothendieck,\nNearest to seven: dolphin, concurrent, honda, dativus, monterey, glue, ecology, gibraltar,\nNearest to if: concurrent, db, columbus, monterey, ak, anarchism, ecology, gibraltar,\nNearest to th: monterey, ecology, honda, concurrent, columbus, db, equ, xm,\nNearest to this: selig, ecology, ada, pl, dativus, homepage, leibniz, malaria,\nNearest to three: xm, concurrent, glue, dolphin, monterey, equ, dativus, import,\nNearest to has: dolphin, cements, xm, damascus, ecology, bwv, monterey, aim,\nNearest to use: monterey, homepage, ecology, el, six, balls, moth, concurrent,\nNearest to also: monterey, tracing, atoll, malaria, ori, batll, xm, honda,\nNearest to however: dive, pl, whisky, columbus, ceres, honda, taylor, ethics,\nNearest to such: concurrent, cnd, ceres, leibniz, ecology, crystals, dativus, blows,\nNearest to eight: dolphin, ecology, monterey, db, honda, emoticons, rover, ntsc,\nNearest to into: ecology, creationism, note, frankfurt, honda, db, tiberius, concurrent,\n\n\nThe experiment completed successfully. Finalizing run...\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n2 items cleaning up...\nCleanup took 0.40442991256713867 seconds\n\nExecution Summary\n=================\nRunId: tf-distr-hvd_1545831657015\n\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "{'runId': 'tf-distr-hvd_1545831657015',\n 'target': 'gpucluster',\n 'status': 'Finalizing',\n 'startTimeUtc': '2018-12-26T13:56:25.844486Z',\n 'properties': {'azureml.runsource': 'experiment',\n  'ContentSnapshotId': 'a99248cd-9630-49d6-ace7-02702182e861'},\n 'runDefinition': {'Script': 'tf_horovod_word2vec.py',\n  'Arguments': ['--input_data',\n   '$AZUREML_DATAREFERENCE_3c18fcc578b242b1a5baa22c0860b576'],\n  'SourceDirectoryDataStore': None,\n  'Framework': 0,\n  'Communicator': 3,\n  'Target': 'gpucluster',\n  'DataReferences': {'3c18fcc578b242b1a5baa22c0860b576': {'DataStoreName': 'workspaceblobstore',\n    'Mode': 'Mount',\n    'PathOnDataStore': 'data/text8.zip',\n    'PathOnCompute': None,\n    'Overwrite': False}},\n  'JobName': None,\n  'AutoPrepareEnvironment': True,\n  'MaxRunDurationSeconds': None,\n  'NodeCount': 2,\n  'Environment': {'Python': {'InterpreterPath': 'python',\n    'UserManagedDependencies': False,\n    'CondaDependencies': {'name': 'project_environment',\n     'dependencies': ['python=3.6.2',\n      {'pip': ['azureml-defaults',\n        'tensorflow-gpu==1.10.0',\n        'horovod==0.13.11']}]},\n    'CondaDependenciesFile': None},\n   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n    'NCCL_SOCKET_IFNAME': '^docker0'},\n   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.0',\n    'Enabled': True,\n    'SharedVolumes': True,\n    'Preparation': None,\n    'GpuSupport': True,\n    'Arguments': [],\n    'BaseImageRegistry': {'Address': None,\n     'Username': None,\n     'Password': None}},\n   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n    'Packages': [{'Group': 'com.microsoft.ml.spark',\n      'Artifact': 'mmlspark_2.11',\n      'Version': '0.12'}],\n    'PrecachePackages': True}},\n  'History': {'OutputCollection': True},\n  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'BatchAi': {'NodeCount': 0},\n  'AmlCompute': {'Name': None,\n   'VmSize': None,\n   'VmPriority': None,\n   'RetainCluster': False,\n   'ClusterMaxNodeCount': 2},\n  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n  'Mpi': {'ProcessCountPerNode': 1},\n  'Hdi': {'YarnDeployMode': 2},\n  'ContainerInstance': {'Region': None, 'CpuCores': 0, 'MemoryGb': 0},\n  'ExposedPorts': None,\n  'PrepareEnvironment': None},\n 'logFiles': {'azureml-logs/60_control_log_rank_0.txt': 'https://amlsworkspace9663571855.blob.core.windows.net/azureml/ExperimentRun/tf-distr-hvd_1545831657015/azureml-logs/60_control_log_rank_0.txt?sv=2018-03-28&sr=b&sig=vmg1XxvrQlAZLbcS9PvHq2SCh1wxWpzI7A6G1TGM8yw%3D&st=2018-12-26T13%3A47%3A58Z&se=2018-12-26T21%3A57%3A58Z&sp=r',\n  'azureml-logs/60_control_log_rank_1.txt': 'https://amlsworkspace9663571855.blob.core.windows.net/azureml/ExperimentRun/tf-distr-hvd_1545831657015/azureml-logs/60_control_log_rank_1.txt?sv=2018-03-28&sr=b&sig=hlK2yivvISiFPpQWqXqtvoyNKWOPazluBVpFfDmlDlw%3D&st=2018-12-26T13%3A47%3A58Z&se=2018-12-26T21%3A57%3A58Z&sp=r',\n  'azureml-logs/80_driver_log_rank_0.txt': 'https://amlsworkspace9663571855.blob.core.windows.net/azureml/ExperimentRun/tf-distr-hvd_1545831657015/azureml-logs/80_driver_log_rank_0.txt?sv=2018-03-28&sr=b&sig=Hb6L9%2FgSsvFDYPiGRodK%2FTOKs3Lwn1ztuii915APb08%3D&st=2018-12-26T13%3A47%3A58Z&se=2018-12-26T21%3A57%3A58Z&sp=r',\n  'azureml-logs/80_driver_log_rank_1.txt': 'https://amlsworkspace9663571855.blob.core.windows.net/azureml/ExperimentRun/tf-distr-hvd_1545831657015/azureml-logs/80_driver_log_rank_1.txt?sv=2018-03-28&sr=b&sig=Cj%2BmkAquHRTDBSqYijYUQVA7aj7Rti8AIGL5KgMPUUw%3D&st=2018-12-26T13%3A47%3A58Z&se=2018-12-26T21%3A57%3A58Z&sp=r',\n  'azureml-logs/azureml.log': 'https://amlsworkspace9663571855.blob.core.windows.net/azureml/ExperimentRun/tf-distr-hvd_1545831657015/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=tmeADdSEemk2c68f%2FqzM1ZMOb9cfr5o0JV0Zqxoke5w%3D&st=2018-12-26T13%3A47%3A58Z&se=2018-12-26T21%3A57%3A58Z&sp=r'}}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "roastala"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "msauthor": "minxia"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}